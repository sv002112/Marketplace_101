{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbd146e-52cd-414e-accf-55bf06274f00",
   "metadata": {},
   "source": [
    "### 1. RandomForestRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18aa3ec1-d8f3-4114-b3d9-724223fff66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved multi-output model to rf_multi_model.joblib\n",
      "Trained and saved avg_rating_model to rf_avg_rating_model.joblib\n",
      "Prediction complete. Output saved to 'variant_predictions_spreadsheet_style_norm.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "TRAIN_MODEL = True  # Set to False to skip training and use saved model\n",
    "MODEL_PATH = 'rf_multi_model.joblib'\n",
    "AVG_MODEL_PATH = 'rf_avg_rating_model.joblib'\n",
    "\n",
    "# ========== Step 1: Load Data ==========\n",
    "train_file = 'Blank rating calculation - Variant Model Train data.csv'\n",
    "variant_file = 'TTI Model Testing - Variant TTI.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "variant_df = pd.read_csv(variant_file)\n",
    "\n",
    "STAR_LIST = [1, 2, 3, 4, 5]\n",
    "\n",
    "# ========== Step 2: Prepare Multi-Output Training Set ==========\n",
    "train_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage'],\n",
    "    fill_value=0\n",
    ")\n",
    "train_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in train_pivot.columns]\n",
    "train_pivot = train_pivot.reset_index()\n",
    "\n",
    "X = train_pivot[[f'Review_{s}' for s in STAR_LIST] + [f'No. of verifiied purchase_{s}' for s in STAR_LIST]].values\n",
    "y = train_pivot[[f'Percentage_{s}' for s in STAR_LIST]].values\n",
    "\n",
    "# ========== Step 3: Train or Load Model ==========\n",
    "if TRAIN_MODEL:\n",
    "    rf_multi = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_multi.fit(X, y)\n",
    "    joblib.dump(rf_multi, MODEL_PATH)\n",
    "    print(f\"Trained and saved multi-output model to {MODEL_PATH}\")\n",
    "else:\n",
    "    rf_multi = joblib.load(MODEL_PATH)\n",
    "    print(f\"Loaded multi-output model from {MODEL_PATH}\")\n",
    "\n",
    "# ========== Helper: Enforce Weighted Star-Combined Percentage ==========\n",
    "def enforce_weighted_star_relation(pred_table, reviews_table, combined_pct, n_iter=6):\n",
    "    pred = pred_table.copy()\n",
    "    for _ in range(n_iter):\n",
    "        pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "        for j in range(5):\n",
    "            weight = reviews_table[:, j]\n",
    "            total_weight = weight.sum()\n",
    "            if total_weight == 0:\n",
    "                continue\n",
    "            weighted_avg = (pred[:, j] * weight).sum() / total_weight\n",
    "            target = combined_pct[j]\n",
    "            if weighted_avg == 0:\n",
    "                scale = 1.0\n",
    "            else:\n",
    "                scale = target / weighted_avg\n",
    "            pred[:, j] = pred[:, j] * scale\n",
    "    pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "    return pred\n",
    "\n",
    "# ========== Step 4: Prepare Variant Data, Predict & Enforce Constraint ==========\n",
    "variant_df['is_combined'] = variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'\n",
    "results = []\n",
    "\n",
    "for (prod, fam), group in variant_df.groupby(['Product', 'Family']):\n",
    "    combined_row = group[group['is_combined']]\n",
    "    variant_rows = group[~group['is_combined']]\n",
    "    if combined_row.empty or variant_rows.empty:\n",
    "        continue\n",
    "\n",
    "    combined_total = combined_row['Total'].iloc[0]\n",
    "    combined_pct = []\n",
    "    for star in STAR_LIST:\n",
    "        row = combined_row[combined_row['Rating'] == star]\n",
    "        combined_pct.append(float(row['Percentage'].iloc[0]) if not row.empty else 0)\n",
    "    combined_pct = np.array(combined_pct)\n",
    "\n",
    "    variants = variant_rows['Variant'].unique()\n",
    "    var_raw_pred = []\n",
    "    var_reviews = []\n",
    "    variant_meta = []\n",
    "\n",
    "    for variant in variants:\n",
    "        var_rows = variant_rows[variant_rows['Variant'] == variant]\n",
    "        feat_review = []\n",
    "        feat_verified = []\n",
    "        star_reviews = []\n",
    "        for star in STAR_LIST:\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            feat_review.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "            feat_verified.append(row['No. of verifiied purchase'].iloc[0] if not row.empty else 0)\n",
    "            star_reviews.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "        features = feat_review + feat_verified\n",
    "        pred_raw = rf_multi.predict([features])[0]\n",
    "        pred_raw = np.maximum(pred_raw, 0)\n",
    "        var_raw_pred.append(pred_raw)\n",
    "        var_reviews.append(star_reviews)\n",
    "        variant_meta.append((variant, var_rows))\n",
    "\n",
    "    var_raw_pred = np.array(var_raw_pred)\n",
    "    var_reviews = np.array(var_reviews)\n",
    "    var_final_pred = enforce_weighted_star_relation(var_raw_pred, var_reviews, combined_pct, n_iter=6)\n",
    "\n",
    "    # Assign predictions back to rows\n",
    "    for i, (variant, var_rows) in enumerate(variant_meta):\n",
    "        for j, star in enumerate(STAR_LIST):\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            if row.empty:\n",
    "                base = var_rows.iloc[0].copy()\n",
    "                base['Rating'] = star\n",
    "                base['Review'] = 0\n",
    "                base['No. of verifiied purchase'] = 0\n",
    "            else:\n",
    "                base = row.iloc[0].copy()\n",
    "            base['pred_Percentage_raw'] = var_raw_pred[i, j]\n",
    "            base['pred_Percentage_first_norm'] = var_final_pred[i, j]\n",
    "            base['combined_Total'] = combined_total\n",
    "            results.append(base)\n",
    "\n",
    "pred_df = pd.DataFrame(results)\n",
    "\n",
    "# ========== Step 5: Spreadsheet formula, per star per product, across variants, EXCLUDING combined ==========\n",
    "def spreadsheet_starwise_norm(df):\n",
    "    norm_col = pd.Series(0.0, index=df.index, dtype=float)\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    df_noncombined = df[mask_noncombined]\n",
    "    for (prod, rating), subdf in df_noncombined.groupby(['Product', 'Rating']):\n",
    "        sum_reviews = subdf['Review'].sum()\n",
    "        for idx, row in subdf.iterrows():\n",
    "            val = (row['Review'] * row['pred_Percentage_first_norm']) / sum_reviews if sum_reviews > 0 else 0\n",
    "            norm_col.at[idx] = val\n",
    "    return norm_col\n",
    "\n",
    "pred_df['pred_Percentage_final_norm'] = spreadsheet_starwise_norm(pred_df)\n",
    "\n",
    "# ========== Step 6: Calculate pred_Total per star ==========\n",
    "pred_df['pred_Total per star'] = (pred_df['pred_Percentage_final_norm'] / 100) * pred_df['combined_Total']\n",
    "pred_df['pred_Total per star'] = pred_df['pred_Total per star'].round().astype(int)\n",
    "\n",
    "# ========== Step 6B: Adjust to match combined variant's Total per star ==========\n",
    "def adjust_pred_total_per_star(df, variant_df):\n",
    "    df = df.copy()\n",
    "    combined_totals = variant_df[variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'].set_index(['Product', 'Rating'])['Total per star'].to_dict()\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    for (product, rating), group in df[mask_noncombined].groupby(['Product', 'Rating']):\n",
    "        combined_total = combined_totals.get((product, rating), 0)\n",
    "        variant_total = group['pred_Total per star'].sum()\n",
    "        difference = combined_total - variant_total\n",
    "        if abs(difference) < 10 and difference != 0:\n",
    "            idx = group['pred_Total per star'].idxmax()\n",
    "            df.loc[idx, 'pred_Total per star'] += difference\n",
    "    return df\n",
    "\n",
    "pred_df = adjust_pred_total_per_star(pred_df, variant_df)\n",
    "\n",
    "# ========== Step 7: Calculate pred_Blank and pred_Total (per variant) ==========\n",
    "pred_df['pred_Blank'] = pred_df['pred_Total per star'] - pred_df['Review']\n",
    "pred_df['pred_Blank'] = pred_df['pred_Blank'].clip(lower=0)\n",
    "pred_df['Total'] = pred_df.groupby(['Product', 'Variant'])['pred_Total per star'].transform('sum')\n",
    "\n",
    "# ========== Step 8: Predict Average Rating (Second Model) ==========\n",
    "avg_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank'],\n",
    "    fill_value=0\n",
    ")\n",
    "avg_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in avg_pivot.columns]\n",
    "avg_pivot = avg_pivot.reset_index()\n",
    "avg_pivot['Total'] = avg_pivot[[f'Total per star_{s}' for s in STAR_LIST]].sum(axis=1)\n",
    "avg_pivot['Average Rating'] = train_df.groupby('Product')['Average Rating'].first().values\n",
    "\n",
    "avg_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank']:\n",
    "    avg_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_features += ['Total']\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    avg_rating_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    avg_rating_model.fit(avg_pivot[avg_features], avg_pivot['Average Rating'])\n",
    "    joblib.dump(avg_rating_model, AVG_MODEL_PATH)\n",
    "    print(f\"Trained and saved avg_rating_model to {AVG_MODEL_PATH}\")\n",
    "else:\n",
    "    avg_rating_model = joblib.load(AVG_MODEL_PATH)\n",
    "    print(f\"Loaded avg_rating_model from {AVG_MODEL_PATH}\")\n",
    "\n",
    "pred_df['Total per star'] = pred_df['pred_Total per star']\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    for s in STAR_LIST:\n",
    "        pred_df[f'{prefix}_{s}'] = pred_df.groupby(['Product', 'Variant'])[prefix].transform(lambda x: list(x) if len(x)==5 else [0]*5)\n",
    "\n",
    "avg_pred_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    avg_pred_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_pred_features += ['Total']\n",
    "\n",
    "for (prod, variant), group in pred_df.groupby(['Product', 'Variant']):\n",
    "    if len(group) != 5:\n",
    "        continue\n",
    "    row = {}\n",
    "    for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "        vals = group[prefix].values\n",
    "        for i, s in enumerate(STAR_LIST):\n",
    "            row[f'{prefix}_{s}'] = vals[i]\n",
    "    row['Total'] = group['Total'].iloc[0]\n",
    "    pred = avg_rating_model.predict([list(row.values())])[0]\n",
    "    pred_df.loc[group.index, 'pred_Average Rating'] = pred\n",
    "\n",
    "# ========== Step 9: Merge with Combined Rows, Preserve Order ==========\n",
    "output_columns = [\n",
    "    'Family', 'Product', 'Variant', 'Rating', 'Review', 'No. of verifiied purchase',\n",
    "    'pred_Percentage_raw', 'pred_Percentage_first_norm', 'pred_Percentage_final_norm',\n",
    "    'pred_Total per star', 'pred_Blank', 'Total', 'pred_Average Rating'\n",
    "]\n",
    "\n",
    "combined_output = variant_df[variant_df['is_combined']].copy()\n",
    "combined_output['pred_Percentage_raw'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_first_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_final_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Total per star'] = combined_output['Total per star']\n",
    "combined_output['pred_Blank'] = combined_output['Blank']\n",
    "combined_output['pred_Average Rating'] = combined_output['Average Rating']\n",
    "combined_output['Total'] = combined_output['Total']\n",
    "combined_output = combined_output[output_columns]\n",
    "\n",
    "final_output = pd.concat([pred_df[output_columns], combined_output], ignore_index=True)\n",
    "\n",
    "# Round pred_Average Rating to 1 decimal\n",
    "final_output['pred_Average Rating'] = final_output['pred_Average Rating'].round(1)\n",
    "\n",
    "# ========== Step 10: Save Output ==========\n",
    "final_output.to_csv('variant_predictions_spreadsheet_style_norm.csv', index=False)\n",
    "print(\"Prediction complete. Output saved to 'variant_predictions_spreadsheet_style_norm.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921f3333-7b61-4929-98d8-9922ae764248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Product</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>No. of verifiied purchase</th>\n",
       "      <th>pred_Percentage_raw</th>\n",
       "      <th>pred_Percentage_first_norm</th>\n",
       "      <th>pred_Percentage_final_norm</th>\n",
       "      <th>pred_Total per star</th>\n",
       "      <th>pred_Blank</th>\n",
       "      <th>Total</th>\n",
       "      <th>pred_Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Hoover Powerscrub</td>\n",
       "      <td>Hoover Powerscrub XL Pet Carpet Cleaner Machin...</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>98</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.448274</td>\n",
       "      <td>0.104101</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Hoover Powerscrub</td>\n",
       "      <td>Hoover Powerscrub XL Pet Carpet Cleaner Machin...</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.183890</td>\n",
       "      <td>0.045316</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Hoover Powerscrub</td>\n",
       "      <td>Hoover Powerscrub XL Pet Carpet Cleaner Machin...</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>5.30</td>\n",
       "      <td>3.023680</td>\n",
       "      <td>0.083634</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Hoover Powerscrub</td>\n",
       "      <td>Hoover Powerscrub XL Pet Carpet Cleaner Machin...</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>12.39</td>\n",
       "      <td>10.989028</td>\n",
       "      <td>0.200321</td>\n",
       "      <td>114.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Hoover Powerscrub</td>\n",
       "      <td>Hoover Powerscrub XL Pet Carpet Cleaner Machin...</td>\n",
       "      <td>5</td>\n",
       "      <td>354</td>\n",
       "      <td>326</td>\n",
       "      <td>75.51</td>\n",
       "      <td>82.355128</td>\n",
       "      <td>2.273903</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Family            Product  \\\n",
       "0  Hoover  Hoover Powerscrub   \n",
       "1  Hoover  Hoover Powerscrub   \n",
       "2  Hoover  Hoover Powerscrub   \n",
       "3  Hoover  Hoover Powerscrub   \n",
       "4  Hoover  Hoover Powerscrub   \n",
       "\n",
       "                                             Variant  Rating  Review  \\\n",
       "0  Hoover Powerscrub XL Pet Carpet Cleaner Machin...       1     110   \n",
       "1  Hoover Powerscrub XL Pet Carpet Cleaner Machin...       2      32   \n",
       "2  Hoover Powerscrub XL Pet Carpet Cleaner Machin...       3      26   \n",
       "3  Hoover Powerscrub XL Pet Carpet Cleaner Machin...       4      49   \n",
       "4  Hoover Powerscrub XL Pet Carpet Cleaner Machin...       5     354   \n",
       "\n",
       "   No. of verifiied purchase  pred_Percentage_raw  pred_Percentage_first_norm  \\\n",
       "0                         98                 4.75                    2.448274   \n",
       "1                         31                 2.05                    1.183890   \n",
       "2                         26                 5.30                    3.023680   \n",
       "3                         46                12.39                   10.989028   \n",
       "4                        326                75.51                   82.355128   \n",
       "\n",
       "   pred_Percentage_final_norm  pred_Total per star  pred_Blank   Total  \\\n",
       "0                    0.104101                 59.0         0.0  1535.0   \n",
       "1                    0.045316                 26.0         0.0  1535.0   \n",
       "2                    0.083634                 47.0        21.0  1535.0   \n",
       "3                    0.200321                114.0        65.0  1535.0   \n",
       "4                    2.273903               1289.0       935.0  1535.0   \n",
       "\n",
       "   pred_Average Rating  \n",
       "0                  4.6  \n",
       "1                  4.6  \n",
       "2                  4.6  \n",
       "3                  4.6  \n",
       "4                  4.6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9a00e-6ac5-4981-9cc9-1fe811c7c3dc",
   "metadata": {},
   "source": [
    "### 2. MultiOutputRegressor with GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66ee299-f82d-4168-ae4d-ab4dd78ca709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved multi-output GradientBoostingRegressor model to gboost_multi_model.joblib\n",
      "Trained and saved avg_rating_model to gboost_avg_rating_model.joblib\n",
      "Prediction complete. Output saved to 'variant_predictions_gboost.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import joblib\n",
    "\n",
    "MODEL_PATH = 'gboost_multi_model.joblib'\n",
    "AVG_MODEL_PATH = 'gboost_avg_rating_model.joblib'\n",
    "\n",
    "train_file = 'Blank rating calculation - Variant Model Train data.csv'\n",
    "variant_file = 'Blank rating calculation - Variant Model Testing data.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "variant_df = pd.read_csv(variant_file)\n",
    "\n",
    "STAR_LIST = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Step 2: Prepare Multi-Output Training Set ===\n",
    "train_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage'],\n",
    "    fill_value=0\n",
    ")\n",
    "train_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in train_pivot.columns]\n",
    "train_pivot = train_pivot.reset_index()\n",
    "\n",
    "X = train_pivot[[f'Review_{s}' for s in STAR_LIST] + [f'No. of verifiied purchase_{s}' for s in STAR_LIST]].values\n",
    "y = train_pivot[[f'Percentage_{s}' for s in STAR_LIST]].values\n",
    "\n",
    "# === Step 3: Train or Load Model ===\n",
    "gboost_multi = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "gboost_multi.fit(X, y)\n",
    "joblib.dump(gboost_multi, MODEL_PATH)\n",
    "print(f\"Trained and saved multi-output GradientBoostingRegressor model to {MODEL_PATH}\")\n",
    "\n",
    "# === Helper: Enforce Weighted Star-Combined Percentage ===\n",
    "def enforce_weighted_star_relation(pred_table, reviews_table, combined_pct, n_iter=6):\n",
    "    pred = pred_table.copy()\n",
    "    for _ in range(n_iter):\n",
    "        pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "        for j in range(5):\n",
    "            weight = reviews_table[:, j]\n",
    "            total_weight = weight.sum()\n",
    "            if total_weight == 0:\n",
    "                continue\n",
    "            weighted_avg = (pred[:, j] * weight).sum() / total_weight\n",
    "            target = combined_pct[j]\n",
    "            scale = target / weighted_avg if weighted_avg != 0 else 1.0\n",
    "            pred[:, j] = pred[:, j] * scale\n",
    "    pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "    return pred\n",
    "\n",
    "# === Step 4+: Predict & Enforce Constraint ===\n",
    "variant_df['is_combined'] = variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'\n",
    "results = []\n",
    "for (prod, fam), group in variant_df.groupby(['Product', 'Family']):\n",
    "    combined_row = group[group['is_combined']]\n",
    "    variant_rows = group[~group['is_combined']]\n",
    "    if combined_row.empty or variant_rows.empty:\n",
    "        continue\n",
    "\n",
    "    combined_total = combined_row['Total'].iloc[0]\n",
    "    combined_pct = []\n",
    "    for star in STAR_LIST:\n",
    "        row = combined_row[combined_row['Rating'] == star]\n",
    "        combined_pct.append(float(row['Percentage'].iloc[0]) if not row.empty else 0)\n",
    "    combined_pct = np.array(combined_pct)\n",
    "\n",
    "    variants = variant_rows['Variant'].unique()\n",
    "    var_raw_pred = []\n",
    "    var_reviews = []\n",
    "    variant_meta = []\n",
    "\n",
    "    for variant in variants:\n",
    "        var_rows = variant_rows[variant_rows['Variant'] == variant]\n",
    "        feat_review = []\n",
    "        feat_verified = []\n",
    "        star_reviews = []\n",
    "        for star in STAR_LIST:\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            feat_review.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "            feat_verified.append(row['No. of verifiied purchase'].iloc[0] if not row.empty else 0)\n",
    "            star_reviews.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "        features = feat_review + feat_verified\n",
    "        pred_raw = gboost_multi.predict([features])[0]\n",
    "        pred_raw = np.maximum(pred_raw, 0)\n",
    "        var_raw_pred.append(pred_raw)\n",
    "        var_reviews.append(star_reviews)\n",
    "        variant_meta.append((variant, var_rows))\n",
    "\n",
    "    var_raw_pred = np.array(var_raw_pred)\n",
    "    var_reviews = np.array(var_reviews)\n",
    "    var_final_pred = enforce_weighted_star_relation(var_raw_pred, var_reviews, combined_pct, n_iter=6)\n",
    "\n",
    "    for i, (variant, var_rows) in enumerate(variant_meta):\n",
    "        for j, star in enumerate(STAR_LIST):\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            if row.empty:\n",
    "                base = var_rows.iloc[0].copy()\n",
    "                base['Rating'] = star\n",
    "                base['Review'] = 0\n",
    "                base['No. of verifiied purchase'] = 0\n",
    "            else:\n",
    "                base = row.iloc[0].copy()\n",
    "            base['pred_Percentage_raw'] = var_raw_pred[i, j]\n",
    "            base['pred_Percentage_first_norm'] = var_final_pred[i, j]\n",
    "            base['combined_Total'] = combined_total\n",
    "            results.append(base)\n",
    "pred_df = pd.DataFrame(results)\n",
    "\n",
    "def spreadsheet_starwise_norm(df):\n",
    "    norm_col = pd.Series(0.0, index=df.index, dtype=float)\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    df_noncombined = df[mask_noncombined]\n",
    "    for (prod, rating), subdf in df_noncombined.groupby(['Product', 'Rating']):\n",
    "        sum_reviews = subdf['Review'].sum()\n",
    "        for idx, row in subdf.iterrows():\n",
    "            val = (row['Review'] * row['pred_Percentage_first_norm']) / sum_reviews if sum_reviews > 0 else 0\n",
    "            norm_col.at[idx] = val\n",
    "    return norm_col\n",
    "\n",
    "pred_df['pred_Percentage_final_norm'] = spreadsheet_starwise_norm(pred_df)\n",
    "pred_df['pred_Total per star'] = (pred_df['pred_Percentage_final_norm'] / 100) * pred_df['combined_Total']\n",
    "pred_df['pred_Total per star'] = pred_df['pred_Total per star'].round().astype(int)\n",
    "\n",
    "def adjust_pred_total_per_star(df, variant_df):\n",
    "    df = df.copy()\n",
    "    combined_totals = variant_df[variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'].set_index(['Product', 'Rating'])['Total per star'].to_dict()\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    for (product, rating), group in df[mask_noncombined].groupby(['Product', 'Rating']):\n",
    "        combined_total = combined_totals.get((product, rating), 0)\n",
    "        variant_total = group['pred_Total per star'].sum()\n",
    "        difference = combined_total - variant_total\n",
    "        if abs(difference) < 10 and difference != 0:\n",
    "            idx = group['pred_Total per star'].idxmax()\n",
    "            df.loc[idx, 'pred_Total per star'] += difference\n",
    "    return df\n",
    "\n",
    "pred_df = adjust_pred_total_per_star(pred_df, variant_df)\n",
    "pred_df['pred_Blank'] = pred_df['pred_Total per star'] - pred_df['Review']\n",
    "pred_df['pred_Blank'] = pred_df['pred_Blank'].clip(lower=0)\n",
    "pred_df['Total'] = pred_df.groupby(['Product', 'Variant'])['pred_Total per star'].transform('sum')\n",
    "\n",
    "# ========== Step 8: Predict Average Rating (Second Model) ==========\n",
    "avg_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank'],\n",
    "    fill_value=0\n",
    ")\n",
    "avg_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in avg_pivot.columns]\n",
    "avg_pivot = avg_pivot.reset_index()\n",
    "avg_pivot['Total'] = avg_pivot[[f'Total per star_{s}' for s in STAR_LIST]].sum(axis=1)\n",
    "avg_pivot['Average Rating'] = train_df.groupby('Product')['Average Rating'].first().values\n",
    "\n",
    "avg_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank']:\n",
    "    avg_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_features += ['Total']\n",
    "\n",
    "avg_rating_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "avg_rating_model.fit(avg_pivot[avg_features], avg_pivot['Average Rating'])\n",
    "joblib.dump(avg_rating_model, AVG_MODEL_PATH)\n",
    "print(f\"Trained and saved avg_rating_model to {AVG_MODEL_PATH}\")\n",
    "\n",
    "pred_df['Total per star'] = pred_df['pred_Total per star']\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    for s in STAR_LIST:\n",
    "        pred_df[f'{prefix}_{s}'] = pred_df.groupby(['Product', 'Variant'])[prefix].transform(lambda x: list(x) if len(x)==5 else [0]*5)\n",
    "\n",
    "avg_pred_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    avg_pred_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_pred_features += ['Total']\n",
    "\n",
    "for (prod, variant), group in pred_df.groupby(['Product', 'Variant']):\n",
    "    if len(group) != 5:\n",
    "        continue\n",
    "    row = {}\n",
    "    for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "        vals = group[prefix].values\n",
    "        for i, s in enumerate(STAR_LIST):\n",
    "            row[f'{prefix}_{s}'] = vals[i]\n",
    "    row['Total'] = group['Total'].iloc[0]\n",
    "    pred = avg_rating_model.predict([list(row.values())])[0]\n",
    "    pred_df.loc[group.index, 'pred_Average Rating'] = pred\n",
    "\n",
    "output_columns = [\n",
    "    'Family', 'Product', 'Variant', 'Rating', 'Review', 'No. of verifiied purchase',\n",
    "    'pred_Percentage_raw', 'pred_Percentage_first_norm', 'pred_Percentage_final_norm',\n",
    "    'pred_Total per star', 'pred_Blank', 'Total', 'pred_Average Rating'\n",
    "]\n",
    "\n",
    "combined_output = variant_df[variant_df['is_combined']].copy()\n",
    "combined_output['pred_Percentage_raw'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_first_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_final_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Total per star'] = combined_output['Total per star']\n",
    "combined_output['pred_Blank'] = combined_output['Blank']\n",
    "combined_output['pred_Average Rating'] = combined_output['Average Rating']\n",
    "combined_output['Total'] = combined_output['Total']\n",
    "combined_output = combined_output[output_columns]\n",
    "\n",
    "final_output = pd.concat([pred_df[output_columns], combined_output], ignore_index=True)\n",
    "final_output['pred_Average Rating'] = final_output['pred_Average Rating'].round(1)\n",
    "final_output.to_csv('variant_predictions_gboost.csv', index=False)\n",
    "print(\"Prediction complete. Output saved to 'variant_predictions_gboost.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44589438-1db9-4c13-b950-7e4cfb96f976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Product</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>No. of verifiied purchase</th>\n",
       "      <th>pred_Percentage_raw</th>\n",
       "      <th>pred_Percentage_first_norm</th>\n",
       "      <th>pred_Percentage_final_norm</th>\n",
       "      <th>pred_Total per star</th>\n",
       "      <th>pred_Blank</th>\n",
       "      <th>Total</th>\n",
       "      <th>pred_Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>443</td>\n",
       "      <td>6.681123</td>\n",
       "      <td>7.234639</td>\n",
       "      <td>6.883869</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>174</td>\n",
       "      <td>3.896681</td>\n",
       "      <td>3.121691</td>\n",
       "      <td>2.907457</td>\n",
       "      <td>453.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>3</td>\n",
       "      <td>238</td>\n",
       "      <td>228</td>\n",
       "      <td>5.153731</td>\n",
       "      <td>5.167415</td>\n",
       "      <td>4.766840</td>\n",
       "      <td>741.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>4</td>\n",
       "      <td>417</td>\n",
       "      <td>395</td>\n",
       "      <td>16.038235</td>\n",
       "      <td>12.244673</td>\n",
       "      <td>11.552101</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>5</td>\n",
       "      <td>1822</td>\n",
       "      <td>1739</td>\n",
       "      <td>62.330626</td>\n",
       "      <td>72.231583</td>\n",
       "      <td>66.635921</td>\n",
       "      <td>10384.0</td>\n",
       "      <td>8562.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Family Product                                Variant  Rating  \\\n",
       "0  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       1   \n",
       "1  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       2   \n",
       "2  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       3   \n",
       "3  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       4   \n",
       "4  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       5   \n",
       "\n",
       "   Review  No. of verifiied purchase  pred_Percentage_raw  \\\n",
       "0     471                        443             6.681123   \n",
       "1     190                        174             3.896681   \n",
       "2     238                        228             5.153731   \n",
       "3     417                        395            16.038235   \n",
       "4    1822                       1739            62.330626   \n",
       "\n",
       "   pred_Percentage_first_norm  pred_Percentage_final_norm  \\\n",
       "0                    7.234639                    6.883869   \n",
       "1                    3.121691                    2.907457   \n",
       "2                    5.167415                    4.766840   \n",
       "3                   12.244673                   11.552101   \n",
       "4                   72.231583                   66.635921   \n",
       "\n",
       "   pred_Total per star  pred_Blank    Total  pred_Average Rating  \n",
       "0               1073.0       602.0  14447.0                  4.3  \n",
       "1                453.0       263.0  14447.0                  4.3  \n",
       "2                741.0       503.0  14447.0                  4.3  \n",
       "3               1796.0      1379.0  14447.0                  4.3  \n",
       "4              10384.0      8562.0  14447.0                  4.3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de4936-ee65-49f7-8998-80127a310c58",
   "metadata": {},
   "source": [
    "### Testing the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52292366-d9f4-47bc-9707-cd5a86a4bc89",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    # Avoid division by zero\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_idx = y_true != 0\n",
    "    return np.mean(np.abs((y_true[non_zero_idx] - y_pred[non_zero_idx]) / y_true[non_zero_idx])) * 100\n",
    "\n",
    "def relative_error(mae, y_true):\n",
    "    # MAE / mean(y_true) as percentage\n",
    "    mean_true = np.mean(np.abs(y_true))\n",
    "    return (mae / mean_true) * 100 if mean_true != 0 else np.nan\n",
    "\n",
    "def regression_accuracy(mae_percent):\n",
    "    # \"Accuracy\" as 100% - MAE % error (not standard, but often requested)\n",
    "    return 100 - mae_percent if not np.isnan(mae_percent) else np.nan\n",
    "\n",
    "def evaluate_model_prediction(\n",
    "    pred_csv_path,\n",
    "    gt_csv_path,\n",
    "    model_name='model'\n",
    "):\n",
    "    pred = pd.read_csv(pred_csv_path)\n",
    "    gt = pd.read_csv(gt_csv_path)\n",
    "    key_cols = ['Product', 'Variant', 'Rating']\n",
    "    merged = pd.merge(pred, gt, on=key_cols, suffixes=('_pred', '_gt'))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Per-star Percentage\n",
    "    if 'pred_Percentage_final_norm' in merged.columns and 'Percentage' in merged.columns:\n",
    "        y_true = merged['Percentage']\n",
    "        y_pred = merged['pred_Percentage_final_norm']\n",
    "        metrics['percentage_mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['percentage_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        metrics['percentage_r2'] = r2_score(y_true, y_pred)\n",
    "        # New metrics\n",
    "        metrics['percentage_mape'] = mean_absolute_percentage_error(y_true, y_pred)\n",
    "        metrics['percentage_mae_percent'] = relative_error(metrics['percentage_mae'], y_true)\n",
    "        metrics['percentage_rmse_percent'] = relative_error(metrics['percentage_rmse'], y_true)\n",
    "        metrics['percentage_regression_accuracy'] = regression_accuracy(metrics['percentage_mae_percent'])\n",
    "    else:\n",
    "        print(f\"[{model_name}] Skipping percentage error: column missing.\")\n",
    "\n",
    "    # Per-star Total per star\n",
    "    if 'pred_Total per star' in merged.columns and 'Total per star' in merged.columns:\n",
    "        y_true = merged['Total per star']\n",
    "        y_pred = merged['pred_Total per star']\n",
    "        metrics['total_per_star_mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['total_per_star_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        metrics['total_per_star_r2'] = r2_score(y_true, y_pred)\n",
    "        # New metrics\n",
    "        metrics['total_per_star_mape'] = mean_absolute_percentage_error(y_true, y_pred)\n",
    "        metrics['total_per_star_mae_percent'] = relative_error(metrics['total_per_star_mae'], y_true)\n",
    "        metrics['total_per_star_rmse_percent'] = relative_error(metrics['total_per_star_rmse'], y_true)\n",
    "        metrics['total_per_star_regression_accuracy'] = regression_accuracy(metrics['total_per_star_mae_percent'])\n",
    "    else:\n",
    "        print(f\"[{model_name}] Skipping total per star error: column missing.\")\n",
    "\n",
    "    # Average Rating (one row per Product/Variant)\n",
    "    if 'pred_Average Rating' in merged.columns and 'Average Rating' in merged.columns:\n",
    "        avg_pred = merged.drop_duplicates(subset=['Product', 'Variant'])[['pred_Average Rating', 'Average Rating']]\n",
    "        y_true = avg_pred['Average Rating']\n",
    "        y_pred = avg_pred['pred_Average Rating']\n",
    "        metrics['avg_rating_mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['avg_rating_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        metrics['avg_rating_r2'] = r2_score(y_true, y_pred)\n",
    "        # New metrics\n",
    "        metrics['avg_rating_mape'] = mean_absolute_percentage_error(y_true, y_pred)\n",
    "        metrics['avg_rating_mae_percent'] = relative_error(metrics['avg_rating_mae'], y_true)\n",
    "        metrics['avg_rating_rmse_percent'] = relative_error(metrics['avg_rating_rmse'], y_true)\n",
    "        metrics['avg_rating_regression_accuracy'] = regression_accuracy(metrics['avg_rating_mae_percent'])\n",
    "    else:\n",
    "        print(f\"[{model_name}] Skipping average rating error: column missing.\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def batch_evaluate(\n",
    "    pred_gt_pairs, # List of (model_name, pred_csv_path, gt_csv_path)\n",
    "    output_csv='model_evaluation_results.csv'\n",
    "):\n",
    "    rows = []\n",
    "    for model_name, pred_csv, gt_csv in pred_gt_pairs:\n",
    "        print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "        metrics = evaluate_model_prediction(pred_csv, gt_csv, model_name=model_name)\n",
    "        metrics['model_name'] = model_name\n",
    "\n",
    "        # Composite metrics\n",
    "        rmse_keys = [k for k in metrics.keys() if k.endswith('_rmse')]\n",
    "        mae_keys  = [k for k in metrics.keys() if k.endswith('_mae')]\n",
    "        r2_keys   = [k for k in metrics.keys() if k.endswith('_r2')]\n",
    "        mape_keys = [k for k in metrics.keys() if k.endswith('_mape')]\n",
    "        mae_percent_keys = [k for k in metrics.keys() if k.endswith('_mae_percent')]\n",
    "        rmse_percent_keys = [k for k in metrics.keys() if k.endswith('_rmse_percent')]\n",
    "        accuracy_keys = [k for k in metrics.keys() if k.endswith('_regression_accuracy')]\n",
    "\n",
    "        # Calculate only if at least one metric is present (avoid division by zero)\n",
    "        metrics['composite_rmse'] = np.mean([metrics[k] for k in rmse_keys if not pd.isnull(metrics[k])]) if rmse_keys else np.nan\n",
    "        metrics['composite_mae']  = np.mean([metrics[k] for k in mae_keys if not pd.isnull(metrics[k])]) if mae_keys else np.nan\n",
    "        metrics['composite_r2']   = np.mean([metrics[k] for k in r2_keys if not pd.isnull(metrics[k])]) if r2_keys else np.nan\n",
    "        metrics['composite_mape'] = np.mean([metrics[k] for k in mape_keys if not pd.isnull(metrics[k])]) if mape_keys else np.nan\n",
    "        metrics['composite_mae_percent'] = np.mean([metrics[k] for k in mae_percent_keys if not pd.isnull(metrics[k])]) if mae_percent_keys else np.nan\n",
    "        metrics['composite_rmse_percent'] = np.mean([metrics[k] for k in rmse_percent_keys if not pd.isnull(metrics[k])]) if rmse_percent_keys else np.nan\n",
    "        metrics['composite_regression_accuracy'] = np.mean([metrics[k] for k in accuracy_keys if not pd.isnull(metrics[k])]) if accuracy_keys else np.nan\n",
    "\n",
    "        rows.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nSaved metrics to {output_csv}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3caacb-bc95-4196-afca-d601d72be86a",
   "metadata": {},
   "source": [
    "# Error and accuracy calculation function\n",
    "pred_gt_pairs = [\n",
    "    (\"RandomForest\", \"variant_predictions_spreadsheet_style_norm.csv\", \"Blank rating calculation - Variant Ground Truth.csv\"),\n",
    "    (\"MultiOutputRegressor with GradientBoostingRegressor\", \"variant_predictions_gboost.csv\", \"Blank rating calculation - Variant Ground Truth.csv\")\n",
    "    # Add more models as needed...\n",
    "]\n",
    "results_df = batch_evaluate(pred_gt_pairs)\n",
    "\n",
    "print(\"MAE (Mean Square Error) - penalizes larger errors more heavily (good if outliers matter to you)\")\n",
    "print(\"RMSE (Root Mean Squared Error) - is more robust to outliers and is the “average error” in the same units as your data\")\n",
    "print(\"R2 (coefficient of determination) - Ranges from -1 to 1, with 1.0 being perfect prediction. Can be interpreted as the proportion of variance explained\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed2b19-78e2-4ccb-aa3a-ac1bbd1ebdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

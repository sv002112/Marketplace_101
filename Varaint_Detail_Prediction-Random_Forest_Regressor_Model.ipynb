{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbd146e-52cd-414e-accf-55bf06274f00",
   "metadata": {},
   "source": [
    "### 1. RandomForestRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18aa3ec1-d8f3-4114-b3d9-724223fff66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved multi-output model to rf_multi_model.joblib\n",
      "Trained and saved avg_rating_model to rf_avg_rating_model.joblib\n",
      "Prediction complete. Output saved to 'variant_predictions_spreadsheet_style_norm.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "TRAIN_MODEL = True  # Set to False to skip training and use saved model\n",
    "MODEL_PATH = 'rf_multi_model.joblib'\n",
    "AVG_MODEL_PATH = 'rf_avg_rating_model.joblib'\n",
    "\n",
    "# ========== Step 1: Load Data ==========\n",
    "train_file = 'Blank rating calculation - Variant Model Train data.csv'\n",
    "variant_file = 'Blank rating calculation - Variant Model Testing data.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "variant_df = pd.read_csv(variant_file)\n",
    "\n",
    "STAR_LIST = [1, 2, 3, 4, 5]\n",
    "\n",
    "# ========== Step 2: Prepare Multi-Output Training Set ==========\n",
    "train_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage'],\n",
    "    fill_value=0\n",
    ")\n",
    "train_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in train_pivot.columns]\n",
    "train_pivot = train_pivot.reset_index()\n",
    "\n",
    "X = train_pivot[[f'Review_{s}' for s in STAR_LIST] + [f'No. of verifiied purchase_{s}' for s in STAR_LIST]].values\n",
    "y = train_pivot[[f'Percentage_{s}' for s in STAR_LIST]].values\n",
    "\n",
    "# ========== Step 3: Train or Load Model ==========\n",
    "if TRAIN_MODEL:\n",
    "    rf_multi = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_multi.fit(X, y)\n",
    "    joblib.dump(rf_multi, MODEL_PATH)\n",
    "    print(f\"Trained and saved multi-output model to {MODEL_PATH}\")\n",
    "else:\n",
    "    rf_multi = joblib.load(MODEL_PATH)\n",
    "    print(f\"Loaded multi-output model from {MODEL_PATH}\")\n",
    "\n",
    "# ========== Helper: Enforce Weighted Star-Combined Percentage ==========\n",
    "def enforce_weighted_star_relation(pred_table, reviews_table, combined_pct, n_iter=6):\n",
    "    pred = pred_table.copy()\n",
    "    for _ in range(n_iter):\n",
    "        pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "        for j in range(5):\n",
    "            weight = reviews_table[:, j]\n",
    "            total_weight = weight.sum()\n",
    "            if total_weight == 0:\n",
    "                continue\n",
    "            weighted_avg = (pred[:, j] * weight).sum() / total_weight\n",
    "            target = combined_pct[j]\n",
    "            if weighted_avg == 0:\n",
    "                scale = 1.0\n",
    "            else:\n",
    "                scale = target / weighted_avg\n",
    "            pred[:, j] = pred[:, j] * scale\n",
    "    pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "    return pred\n",
    "\n",
    "# ========== Step 4: Prepare Variant Data, Predict & Enforce Constraint ==========\n",
    "variant_df['is_combined'] = variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'\n",
    "results = []\n",
    "\n",
    "for (prod, fam), group in variant_df.groupby(['Product', 'Family']):\n",
    "    combined_row = group[group['is_combined']]\n",
    "    variant_rows = group[~group['is_combined']]\n",
    "    if combined_row.empty or variant_rows.empty:\n",
    "        continue\n",
    "\n",
    "    combined_total = combined_row['Total'].iloc[0]\n",
    "    combined_pct = []\n",
    "    for star in STAR_LIST:\n",
    "        row = combined_row[combined_row['Rating'] == star]\n",
    "        combined_pct.append(float(row['Percentage'].iloc[0]) if not row.empty else 0)\n",
    "    combined_pct = np.array(combined_pct)\n",
    "\n",
    "    variants = variant_rows['Variant'].unique()\n",
    "    var_raw_pred = []\n",
    "    var_reviews = []\n",
    "    variant_meta = []\n",
    "\n",
    "    for variant in variants:\n",
    "        var_rows = variant_rows[variant_rows['Variant'] == variant]\n",
    "        feat_review = []\n",
    "        feat_verified = []\n",
    "        star_reviews = []\n",
    "        for star in STAR_LIST:\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            feat_review.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "            feat_verified.append(row['No. of verifiied purchase'].iloc[0] if not row.empty else 0)\n",
    "            star_reviews.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "        features = feat_review + feat_verified\n",
    "        pred_raw = rf_multi.predict([features])[0]\n",
    "        pred_raw = np.maximum(pred_raw, 0)\n",
    "        var_raw_pred.append(pred_raw)\n",
    "        var_reviews.append(star_reviews)\n",
    "        variant_meta.append((variant, var_rows))\n",
    "\n",
    "    var_raw_pred = np.array(var_raw_pred)\n",
    "    var_reviews = np.array(var_reviews)\n",
    "    var_final_pred = enforce_weighted_star_relation(var_raw_pred, var_reviews, combined_pct, n_iter=6)\n",
    "\n",
    "    # Assign predictions back to rows\n",
    "    for i, (variant, var_rows) in enumerate(variant_meta):\n",
    "        for j, star in enumerate(STAR_LIST):\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            if row.empty:\n",
    "                base = var_rows.iloc[0].copy()\n",
    "                base['Rating'] = star\n",
    "                base['Review'] = 0\n",
    "                base['No. of verifiied purchase'] = 0\n",
    "            else:\n",
    "                base = row.iloc[0].copy()\n",
    "            base['pred_Percentage_raw'] = var_raw_pred[i, j]\n",
    "            base['pred_Percentage_first_norm'] = var_final_pred[i, j]\n",
    "            base['combined_Total'] = combined_total\n",
    "            results.append(base)\n",
    "\n",
    "pred_df = pd.DataFrame(results)\n",
    "\n",
    "# ========== Step 5: Spreadsheet formula, per star per product, across variants, EXCLUDING combined ==========\n",
    "def spreadsheet_starwise_norm(df):\n",
    "    norm_col = pd.Series(0.0, index=df.index, dtype=float)\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    df_noncombined = df[mask_noncombined]\n",
    "    for (prod, rating), subdf in df_noncombined.groupby(['Product', 'Rating']):\n",
    "        sum_reviews = subdf['Review'].sum()\n",
    "        for idx, row in subdf.iterrows():\n",
    "            val = (row['Review'] * row['pred_Percentage_first_norm']) / sum_reviews if sum_reviews > 0 else 0\n",
    "            norm_col.at[idx] = val\n",
    "    return norm_col\n",
    "\n",
    "pred_df['pred_Percentage_final_norm'] = spreadsheet_starwise_norm(pred_df)\n",
    "\n",
    "# ========== Step 6: Calculate pred_Total per star ==========\n",
    "pred_df['pred_Total per star'] = (pred_df['pred_Percentage_final_norm'] / 100) * pred_df['combined_Total']\n",
    "pred_df['pred_Total per star'] = pred_df['pred_Total per star'].round().astype(int)\n",
    "\n",
    "# ========== Step 6B: Adjust to match combined variant's Total per star ==========\n",
    "def adjust_pred_total_per_star(df, variant_df):\n",
    "    df = df.copy()\n",
    "    combined_totals = variant_df[variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'].set_index(['Product', 'Rating'])['Total per star'].to_dict()\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    for (product, rating), group in df[mask_noncombined].groupby(['Product', 'Rating']):\n",
    "        combined_total = combined_totals.get((product, rating), 0)\n",
    "        variant_total = group['pred_Total per star'].sum()\n",
    "        difference = combined_total - variant_total\n",
    "        if abs(difference) < 10 and difference != 0:\n",
    "            idx = group['pred_Total per star'].idxmax()\n",
    "            df.loc[idx, 'pred_Total per star'] += difference\n",
    "    return df\n",
    "\n",
    "pred_df = adjust_pred_total_per_star(pred_df, variant_df)\n",
    "\n",
    "# ========== Step 7: Calculate pred_Blank and pred_Total (per variant) ==========\n",
    "pred_df['pred_Blank'] = pred_df['pred_Total per star'] - pred_df['Review']\n",
    "pred_df['pred_Blank'] = pred_df['pred_Blank'].clip(lower=0)\n",
    "pred_df['Total'] = pred_df.groupby(['Product', 'Variant'])['pred_Total per star'].transform('sum')\n",
    "\n",
    "# ========== Step 8: Predict Average Rating (Second Model) ==========\n",
    "avg_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank'],\n",
    "    fill_value=0\n",
    ")\n",
    "avg_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in avg_pivot.columns]\n",
    "avg_pivot = avg_pivot.reset_index()\n",
    "avg_pivot['Total'] = avg_pivot[[f'Total per star_{s}' for s in STAR_LIST]].sum(axis=1)\n",
    "avg_pivot['Average Rating'] = train_df.groupby('Product')['Average Rating'].first().values\n",
    "\n",
    "avg_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank']:\n",
    "    avg_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_features += ['Total']\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    avg_rating_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    avg_rating_model.fit(avg_pivot[avg_features], avg_pivot['Average Rating'])\n",
    "    joblib.dump(avg_rating_model, AVG_MODEL_PATH)\n",
    "    print(f\"Trained and saved avg_rating_model to {AVG_MODEL_PATH}\")\n",
    "else:\n",
    "    avg_rating_model = joblib.load(AVG_MODEL_PATH)\n",
    "    print(f\"Loaded avg_rating_model from {AVG_MODEL_PATH}\")\n",
    "\n",
    "pred_df['Total per star'] = pred_df['pred_Total per star']\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    for s in STAR_LIST:\n",
    "        pred_df[f'{prefix}_{s}'] = pred_df.groupby(['Product', 'Variant'])[prefix].transform(lambda x: list(x) if len(x)==5 else [0]*5)\n",
    "\n",
    "avg_pred_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    avg_pred_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_pred_features += ['Total']\n",
    "\n",
    "for (prod, variant), group in pred_df.groupby(['Product', 'Variant']):\n",
    "    if len(group) != 5:\n",
    "        continue\n",
    "    row = {}\n",
    "    for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "        vals = group[prefix].values\n",
    "        for i, s in enumerate(STAR_LIST):\n",
    "            row[f'{prefix}_{s}'] = vals[i]\n",
    "    row['Total'] = group['Total'].iloc[0]\n",
    "    pred = avg_rating_model.predict([list(row.values())])[0]\n",
    "    pred_df.loc[group.index, 'pred_Average Rating'] = pred\n",
    "\n",
    "# ========== Step 9: Merge with Combined Rows, Preserve Order ==========\n",
    "output_columns = [\n",
    "    'Family', 'Product', 'Variant', 'Rating', 'Review', 'No. of verifiied purchase',\n",
    "    'pred_Percentage_raw', 'pred_Percentage_first_norm', 'pred_Percentage_final_norm',\n",
    "    'pred_Total per star', 'pred_Blank', 'Total', 'pred_Average Rating'\n",
    "]\n",
    "\n",
    "combined_output = variant_df[variant_df['is_combined']].copy()\n",
    "combined_output['pred_Percentage_raw'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_first_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_final_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Total per star'] = combined_output['Total per star']\n",
    "combined_output['pred_Blank'] = combined_output['Blank']\n",
    "combined_output['pred_Average Rating'] = combined_output['Average Rating']\n",
    "combined_output['Total'] = combined_output['Total']\n",
    "combined_output = combined_output[output_columns]\n",
    "\n",
    "final_output = pd.concat([pred_df[output_columns], combined_output], ignore_index=True)\n",
    "\n",
    "# Round pred_Average Rating to 1 decimal\n",
    "final_output['pred_Average Rating'] = final_output['pred_Average Rating'].round(1)\n",
    "\n",
    "# ========== Step 10: Save Output ==========\n",
    "final_output.to_csv('variant_predictions_spreadsheet_style_norm.csv', index=False)\n",
    "print(\"Prediction complete. Output saved to 'variant_predictions_spreadsheet_style_norm.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921f3333-7b61-4929-98d8-9922ae764248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Product</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>No. of verifiied purchase</th>\n",
       "      <th>pred_Percentage_raw</th>\n",
       "      <th>pred_Percentage_first_norm</th>\n",
       "      <th>pred_Percentage_final_norm</th>\n",
       "      <th>pred_Total per star</th>\n",
       "      <th>pred_Blank</th>\n",
       "      <th>Total</th>\n",
       "      <th>pred_Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>443</td>\n",
       "      <td>6.11</td>\n",
       "      <td>7.141713</td>\n",
       "      <td>6.795449</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>14448.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>174</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.062538</td>\n",
       "      <td>2.852364</td>\n",
       "      <td>444.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>14448.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>3</td>\n",
       "      <td>238</td>\n",
       "      <td>228</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.115313</td>\n",
       "      <td>4.718777</td>\n",
       "      <td>734.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>14448.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>4</td>\n",
       "      <td>417</td>\n",
       "      <td>395</td>\n",
       "      <td>14.62</td>\n",
       "      <td>12.186614</td>\n",
       "      <td>11.497326</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>14448.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>5</td>\n",
       "      <td>1822</td>\n",
       "      <td>1739</td>\n",
       "      <td>70.83</td>\n",
       "      <td>72.493821</td>\n",
       "      <td>66.877844</td>\n",
       "      <td>10422.0</td>\n",
       "      <td>8600.0</td>\n",
       "      <td>14448.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Family Product                                Variant  Rating  \\\n",
       "0  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       1   \n",
       "1  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       2   \n",
       "2  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       3   \n",
       "3  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       4   \n",
       "4  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       5   \n",
       "\n",
       "   Review  No. of verifiied purchase  pred_Percentage_raw  \\\n",
       "0     471                        443                 6.11   \n",
       "1     190                        174                 2.71   \n",
       "2     238                        228                 5.73   \n",
       "3     417                        395                14.62   \n",
       "4    1822                       1739                70.83   \n",
       "\n",
       "   pred_Percentage_first_norm  pred_Percentage_final_norm  \\\n",
       "0                    7.141713                    6.795449   \n",
       "1                    3.062538                    2.852364   \n",
       "2                    5.115313                    4.718777   \n",
       "3                   12.186614                   11.497326   \n",
       "4                   72.493821                   66.877844   \n",
       "\n",
       "   pred_Total per star  pred_Blank    Total  pred_Average Rating  \n",
       "0               1059.0       588.0  14448.0                  4.3  \n",
       "1                444.0       254.0  14448.0                  4.3  \n",
       "2                734.0       496.0  14448.0                  4.3  \n",
       "3               1789.0      1372.0  14448.0                  4.3  \n",
       "4              10422.0      8600.0  14448.0                  4.3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9a00e-6ac5-4981-9cc9-1fe811c7c3dc",
   "metadata": {},
   "source": [
    "### 2. MultiOutputRegressor with GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66ee299-f82d-4168-ae4d-ab4dd78ca709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved multi-output GradientBoostingRegressor model to gboost_multi_model.joblib\n",
      "Trained and saved avg_rating_model to gboost_avg_rating_model.joblib\n",
      "Prediction complete. Output saved to 'variant_predictions_gboost.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import joblib\n",
    "\n",
    "MODEL_PATH = 'gboost_multi_model.joblib'\n",
    "AVG_MODEL_PATH = 'gboost_avg_rating_model.joblib'\n",
    "\n",
    "train_file = 'Blank rating calculation - Variant Model Train data.csv'\n",
    "variant_file = 'Blank rating calculation - Variant Model Testing data.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "variant_df = pd.read_csv(variant_file)\n",
    "\n",
    "STAR_LIST = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Step 2: Prepare Multi-Output Training Set ===\n",
    "train_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage'],\n",
    "    fill_value=0\n",
    ")\n",
    "train_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in train_pivot.columns]\n",
    "train_pivot = train_pivot.reset_index()\n",
    "\n",
    "X = train_pivot[[f'Review_{s}' for s in STAR_LIST] + [f'No. of verifiied purchase_{s}' for s in STAR_LIST]].values\n",
    "y = train_pivot[[f'Percentage_{s}' for s in STAR_LIST]].values\n",
    "\n",
    "# === Step 3: Train or Load Model ===\n",
    "gboost_multi = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "gboost_multi.fit(X, y)\n",
    "joblib.dump(gboost_multi, MODEL_PATH)\n",
    "print(f\"Trained and saved multi-output GradientBoostingRegressor model to {MODEL_PATH}\")\n",
    "\n",
    "# === Helper: Enforce Weighted Star-Combined Percentage ===\n",
    "def enforce_weighted_star_relation(pred_table, reviews_table, combined_pct, n_iter=6):\n",
    "    pred = pred_table.copy()\n",
    "    for _ in range(n_iter):\n",
    "        pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "        for j in range(5):\n",
    "            weight = reviews_table[:, j]\n",
    "            total_weight = weight.sum()\n",
    "            if total_weight == 0:\n",
    "                continue\n",
    "            weighted_avg = (pred[:, j] * weight).sum() / total_weight\n",
    "            target = combined_pct[j]\n",
    "            scale = target / weighted_avg if weighted_avg != 0 else 1.0\n",
    "            pred[:, j] = pred[:, j] * scale\n",
    "    pred = pred / pred.sum(axis=1, keepdims=True) * 100\n",
    "    return pred\n",
    "\n",
    "# === Step 4+: Predict & Enforce Constraint ===\n",
    "variant_df['is_combined'] = variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'\n",
    "results = []\n",
    "for (prod, fam), group in variant_df.groupby(['Product', 'Family']):\n",
    "    combined_row = group[group['is_combined']]\n",
    "    variant_rows = group[~group['is_combined']]\n",
    "    if combined_row.empty or variant_rows.empty:\n",
    "        continue\n",
    "\n",
    "    combined_total = combined_row['Total'].iloc[0]\n",
    "    combined_pct = []\n",
    "    for star in STAR_LIST:\n",
    "        row = combined_row[combined_row['Rating'] == star]\n",
    "        combined_pct.append(float(row['Percentage'].iloc[0]) if not row.empty else 0)\n",
    "    combined_pct = np.array(combined_pct)\n",
    "\n",
    "    variants = variant_rows['Variant'].unique()\n",
    "    var_raw_pred = []\n",
    "    var_reviews = []\n",
    "    variant_meta = []\n",
    "\n",
    "    for variant in variants:\n",
    "        var_rows = variant_rows[variant_rows['Variant'] == variant]\n",
    "        feat_review = []\n",
    "        feat_verified = []\n",
    "        star_reviews = []\n",
    "        for star in STAR_LIST:\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            feat_review.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "            feat_verified.append(row['No. of verifiied purchase'].iloc[0] if not row.empty else 0)\n",
    "            star_reviews.append(row['Review'].iloc[0] if not row.empty else 0)\n",
    "        features = feat_review + feat_verified\n",
    "        pred_raw = gboost_multi.predict([features])[0]\n",
    "        pred_raw = np.maximum(pred_raw, 0)\n",
    "        var_raw_pred.append(pred_raw)\n",
    "        var_reviews.append(star_reviews)\n",
    "        variant_meta.append((variant, var_rows))\n",
    "\n",
    "    var_raw_pred = np.array(var_raw_pred)\n",
    "    var_reviews = np.array(var_reviews)\n",
    "    var_final_pred = enforce_weighted_star_relation(var_raw_pred, var_reviews, combined_pct, n_iter=6)\n",
    "\n",
    "    for i, (variant, var_rows) in enumerate(variant_meta):\n",
    "        for j, star in enumerate(STAR_LIST):\n",
    "            row = var_rows[var_rows['Rating'] == star]\n",
    "            if row.empty:\n",
    "                base = var_rows.iloc[0].copy()\n",
    "                base['Rating'] = star\n",
    "                base['Review'] = 0\n",
    "                base['No. of verifiied purchase'] = 0\n",
    "            else:\n",
    "                base = row.iloc[0].copy()\n",
    "            base['pred_Percentage_raw'] = var_raw_pred[i, j]\n",
    "            base['pred_Percentage_first_norm'] = var_final_pred[i, j]\n",
    "            base['combined_Total'] = combined_total\n",
    "            results.append(base)\n",
    "pred_df = pd.DataFrame(results)\n",
    "\n",
    "def spreadsheet_starwise_norm(df):\n",
    "    norm_col = pd.Series(0.0, index=df.index, dtype=float)\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    df_noncombined = df[mask_noncombined]\n",
    "    for (prod, rating), subdf in df_noncombined.groupby(['Product', 'Rating']):\n",
    "        sum_reviews = subdf['Review'].sum()\n",
    "        for idx, row in subdf.iterrows():\n",
    "            val = (row['Review'] * row['pred_Percentage_first_norm']) / sum_reviews if sum_reviews > 0 else 0\n",
    "            norm_col.at[idx] = val\n",
    "    return norm_col\n",
    "\n",
    "pred_df['pred_Percentage_final_norm'] = spreadsheet_starwise_norm(pred_df)\n",
    "pred_df['pred_Total per star'] = (pred_df['pred_Percentage_final_norm'] / 100) * pred_df['combined_Total']\n",
    "pred_df['pred_Total per star'] = pred_df['pred_Total per star'].round().astype(int)\n",
    "\n",
    "def adjust_pred_total_per_star(df, variant_df):\n",
    "    df = df.copy()\n",
    "    combined_totals = variant_df[variant_df['Variant'].astype(str).str.strip().str.lower() == 'combined'].set_index(['Product', 'Rating'])['Total per star'].to_dict()\n",
    "    mask_noncombined = ~df['Variant'].astype(str).str.strip().str.lower().eq('combined')\n",
    "    for (product, rating), group in df[mask_noncombined].groupby(['Product', 'Rating']):\n",
    "        combined_total = combined_totals.get((product, rating), 0)\n",
    "        variant_total = group['pred_Total per star'].sum()\n",
    "        difference = combined_total - variant_total\n",
    "        if abs(difference) < 10 and difference != 0:\n",
    "            idx = group['pred_Total per star'].idxmax()\n",
    "            df.loc[idx, 'pred_Total per star'] += difference\n",
    "    return df\n",
    "\n",
    "pred_df = adjust_pred_total_per_star(pred_df, variant_df)\n",
    "pred_df['pred_Blank'] = pred_df['pred_Total per star'] - pred_df['Review']\n",
    "pred_df['pred_Blank'] = pred_df['pred_Blank'].clip(lower=0)\n",
    "pred_df['Total'] = pred_df.groupby(['Product', 'Variant'])['pred_Total per star'].transform('sum')\n",
    "\n",
    "# ========== Step 8: Predict Average Rating (Second Model) ==========\n",
    "avg_pivot = train_df.pivot_table(\n",
    "    index=['Product'],\n",
    "    columns='Rating',\n",
    "    values=['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank'],\n",
    "    fill_value=0\n",
    ")\n",
    "avg_pivot.columns = ['{}_{}'.format(col[0], int(col[1])) for col in avg_pivot.columns]\n",
    "avg_pivot = avg_pivot.reset_index()\n",
    "avg_pivot['Total'] = avg_pivot[[f'Total per star_{s}' for s in STAR_LIST]].sum(axis=1)\n",
    "avg_pivot['Average Rating'] = train_df.groupby('Product')['Average Rating'].first().values\n",
    "\n",
    "avg_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'Percentage', 'Total per star', 'Blank']:\n",
    "    avg_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_features += ['Total']\n",
    "\n",
    "avg_rating_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "avg_rating_model.fit(avg_pivot[avg_features], avg_pivot['Average Rating'])\n",
    "joblib.dump(avg_rating_model, AVG_MODEL_PATH)\n",
    "print(f\"Trained and saved avg_rating_model to {AVG_MODEL_PATH}\")\n",
    "\n",
    "pred_df['Total per star'] = pred_df['pred_Total per star']\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    for s in STAR_LIST:\n",
    "        pred_df[f'{prefix}_{s}'] = pred_df.groupby(['Product', 'Variant'])[prefix].transform(lambda x: list(x) if len(x)==5 else [0]*5)\n",
    "\n",
    "avg_pred_features = []\n",
    "for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "    avg_pred_features += [f'{prefix}_{s}' for s in STAR_LIST]\n",
    "avg_pred_features += ['Total']\n",
    "\n",
    "for (prod, variant), group in pred_df.groupby(['Product', 'Variant']):\n",
    "    if len(group) != 5:\n",
    "        continue\n",
    "    row = {}\n",
    "    for prefix in ['Review', 'No. of verifiied purchase', 'pred_Percentage_first_norm', 'pred_Total per star', 'pred_Blank']:\n",
    "        vals = group[prefix].values\n",
    "        for i, s in enumerate(STAR_LIST):\n",
    "            row[f'{prefix}_{s}'] = vals[i]\n",
    "    row['Total'] = group['Total'].iloc[0]\n",
    "    pred = avg_rating_model.predict([list(row.values())])[0]\n",
    "    pred_df.loc[group.index, 'pred_Average Rating'] = pred\n",
    "\n",
    "output_columns = [\n",
    "    'Family', 'Product', 'Variant', 'Rating', 'Review', 'No. of verifiied purchase',\n",
    "    'pred_Percentage_raw', 'pred_Percentage_first_norm', 'pred_Percentage_final_norm',\n",
    "    'pred_Total per star', 'pred_Blank', 'Total', 'pred_Average Rating'\n",
    "]\n",
    "\n",
    "combined_output = variant_df[variant_df['is_combined']].copy()\n",
    "combined_output['pred_Percentage_raw'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_first_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Percentage_final_norm'] = combined_output['Percentage']\n",
    "combined_output['pred_Total per star'] = combined_output['Total per star']\n",
    "combined_output['pred_Blank'] = combined_output['Blank']\n",
    "combined_output['pred_Average Rating'] = combined_output['Average Rating']\n",
    "combined_output['Total'] = combined_output['Total']\n",
    "combined_output = combined_output[output_columns]\n",
    "\n",
    "final_output = pd.concat([pred_df[output_columns], combined_output], ignore_index=True)\n",
    "final_output['pred_Average Rating'] = final_output['pred_Average Rating'].round(1)\n",
    "final_output.to_csv('variant_predictions_gboost.csv', index=False)\n",
    "print(\"Prediction complete. Output saved to 'variant_predictions_gboost.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44589438-1db9-4c13-b950-7e4cfb96f976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Product</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>No. of verifiied purchase</th>\n",
       "      <th>pred_Percentage_raw</th>\n",
       "      <th>pred_Percentage_first_norm</th>\n",
       "      <th>pred_Percentage_final_norm</th>\n",
       "      <th>pred_Total per star</th>\n",
       "      <th>pred_Blank</th>\n",
       "      <th>Total</th>\n",
       "      <th>pred_Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>443</td>\n",
       "      <td>6.681123</td>\n",
       "      <td>7.234639</td>\n",
       "      <td>6.883869</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>174</td>\n",
       "      <td>3.896681</td>\n",
       "      <td>3.121691</td>\n",
       "      <td>2.907457</td>\n",
       "      <td>453.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>3</td>\n",
       "      <td>238</td>\n",
       "      <td>228</td>\n",
       "      <td>5.153731</td>\n",
       "      <td>5.167415</td>\n",
       "      <td>4.766840</td>\n",
       "      <td>741.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>4</td>\n",
       "      <td>417</td>\n",
       "      <td>395</td>\n",
       "      <td>16.038235</td>\n",
       "      <td>12.244673</td>\n",
       "      <td>11.552101</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryobi - Competitor</td>\n",
       "      <td>Blower</td>\n",
       "      <td>DEWALT 20V MAX Compact Jobsite Blower</td>\n",
       "      <td>5</td>\n",
       "      <td>1822</td>\n",
       "      <td>1739</td>\n",
       "      <td>62.330626</td>\n",
       "      <td>72.231583</td>\n",
       "      <td>66.635921</td>\n",
       "      <td>10384.0</td>\n",
       "      <td>8562.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Family Product                                Variant  Rating  \\\n",
       "0  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       1   \n",
       "1  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       2   \n",
       "2  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       3   \n",
       "3  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       4   \n",
       "4  Ryobi - Competitor  Blower  DEWALT 20V MAX Compact Jobsite Blower       5   \n",
       "\n",
       "   Review  No. of verifiied purchase  pred_Percentage_raw  \\\n",
       "0     471                        443             6.681123   \n",
       "1     190                        174             3.896681   \n",
       "2     238                        228             5.153731   \n",
       "3     417                        395            16.038235   \n",
       "4    1822                       1739            62.330626   \n",
       "\n",
       "   pred_Percentage_first_norm  pred_Percentage_final_norm  \\\n",
       "0                    7.234639                    6.883869   \n",
       "1                    3.121691                    2.907457   \n",
       "2                    5.167415                    4.766840   \n",
       "3                   12.244673                   11.552101   \n",
       "4                   72.231583                   66.635921   \n",
       "\n",
       "   pred_Total per star  pred_Blank    Total  pred_Average Rating  \n",
       "0               1073.0       602.0  14447.0                  4.3  \n",
       "1                453.0       263.0  14447.0                  4.3  \n",
       "2                741.0       503.0  14447.0                  4.3  \n",
       "3               1796.0      1379.0  14447.0                  4.3  \n",
       "4              10384.0      8562.0  14447.0                  4.3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de4936-ee65-49f7-8998-80127a310c58",
   "metadata": {},
   "source": [
    "### Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee3eb2d-e289-41f7-b9e0-02f60fe978b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model_prediction(\n",
    "    pred_csv_path,\n",
    "    gt_csv_path,\n",
    "    model_name='model'\n",
    "):\n",
    "    pred = pd.read_csv(pred_csv_path)\n",
    "    gt = pd.read_csv(gt_csv_path)\n",
    "    key_cols = ['Product', 'Variant', 'Rating']\n",
    "    merged = pd.merge(pred, gt, on=key_cols, suffixes=('_pred', '_gt'))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Per-star Percentage\n",
    "    if 'pred_Percentage_final_norm' in merged.columns and 'Percentage' in merged.columns:\n",
    "        y_true = merged['Percentage']\n",
    "        y_pred = merged['pred_Percentage_final_norm']\n",
    "        metrics['percentage_mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['percentage_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        metrics['percentage_r2'] = r2_score(y_true, y_pred)\n",
    "    else:\n",
    "        print(f\"[{model_name}] Skipping percentage error: column missing.\")\n",
    "\n",
    "    # Per-star Total per star\n",
    "    if 'pred_Total per star' in merged.columns and 'Total per star' in merged.columns:\n",
    "        y_true = merged['Total per star']\n",
    "        y_pred = merged['pred_Total per star']\n",
    "        metrics['total_per_star_mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['total_per_star_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        metrics['total_per_star_r2'] = r2_score(y_true, y_pred)\n",
    "    else:\n",
    "        print(f\"[{model_name}] Skipping total per star error: column missing.\")\n",
    "\n",
    "    # Average Rating (one row per Product/Variant)\n",
    "    if 'pred_Average Rating' in merged.columns and 'Average Rating' in merged.columns:\n",
    "        avg_pred = merged.drop_duplicates(subset=['Product', 'Variant'])[['pred_Average Rating', 'Average Rating']]\n",
    "        y_true = avg_pred['Average Rating']\n",
    "        y_pred = avg_pred['pred_Average Rating']\n",
    "        metrics['avg_rating_mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['avg_rating_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        metrics['avg_rating_r2'] = r2_score(y_true, y_pred)\n",
    "    else:\n",
    "        print(f\"[{model_name}] Skipping average rating error: column missing.\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def batch_evaluate(\n",
    "    pred_gt_pairs, # List of (model_name, pred_csv_path, gt_csv_path)\n",
    "    output_csv='model_evaluation_results.csv'\n",
    "):\n",
    "    rows = []\n",
    "    for model_name, pred_csv, gt_csv in pred_gt_pairs:\n",
    "        print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "        metrics = evaluate_model_prediction(pred_csv, gt_csv, model_name=model_name)\n",
    "        metrics['model_name'] = model_name\n",
    "\n",
    "        # Composite metrics\n",
    "        rmse_keys = [k for k in metrics.keys() if k.endswith('_rmse')]\n",
    "        mae_keys  = [k for k in metrics.keys() if k.endswith('_mae')]\n",
    "        r2_keys   = [k for k in metrics.keys() if k.endswith('_r2')]\n",
    "        # Calculate only if at least one metric is present (avoid division by zero)\n",
    "        metrics['composite_rmse'] = np.mean([metrics[k] for k in rmse_keys if not pd.isnull(metrics[k])]) if rmse_keys else np.nan\n",
    "        metrics['composite_mae']  = np.mean([metrics[k] for k in mae_keys if not pd.isnull(metrics[k])]) if mae_keys else np.nan\n",
    "        metrics['composite_r2']   = np.mean([metrics[k] for k in r2_keys if not pd.isnull(metrics[k])]) if r2_keys else np.nan\n",
    "\n",
    "        rows.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nSaved metrics to {output_csv}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b762c12f-af61-48ee-b227-d576720b738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating RandomForest ===\n",
      "\n",
      "=== Evaluating MultiOutputRegressor with GradientBoostingRegressor ===\n",
      "\n",
      "Saved metrics to model_evaluation_results.csv\n",
      "MAE (Mean Square Error) - penalizes larger errors more heavily (good if outliers matter to you)\n",
      "RMSE (Root Mean Squared Error) - is more robust to outliers and is the “average error” in the same units as your data\n",
      "R2 (coefficient of determination) - Ranges from 0 to 1, with 1.0 being perfect prediction. Can be interpreted as the proportion of variance explained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage_mae</th>\n",
       "      <th>percentage_rmse</th>\n",
       "      <th>percentage_r2</th>\n",
       "      <th>total_per_star_mae</th>\n",
       "      <th>total_per_star_rmse</th>\n",
       "      <th>total_per_star_r2</th>\n",
       "      <th>avg_rating_mae</th>\n",
       "      <th>avg_rating_rmse</th>\n",
       "      <th>avg_rating_r2</th>\n",
       "      <th>model_name</th>\n",
       "      <th>composite_rmse</th>\n",
       "      <th>composite_mae</th>\n",
       "      <th>composite_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.005766</td>\n",
       "      <td>17.649628</td>\n",
       "      <td>0.430555</td>\n",
       "      <td>279.44</td>\n",
       "      <td>928.528169</td>\n",
       "      <td>0.964295</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.114018</td>\n",
       "      <td>0.856195</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>315.430605</td>\n",
       "      <td>95.838589</td>\n",
       "      <td>0.750348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.005559</td>\n",
       "      <td>17.627335</td>\n",
       "      <td>0.431992</td>\n",
       "      <td>281.76</td>\n",
       "      <td>957.028735</td>\n",
       "      <td>0.962069</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.126491</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>MultiOutputRegressor with GradientBoostingRegr...</td>\n",
       "      <td>324.927520</td>\n",
       "      <td>96.615186</td>\n",
       "      <td>0.739023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percentage_mae  percentage_rmse  percentage_r2  total_per_star_mae  \\\n",
       "0        8.005766        17.649628       0.430555              279.44   \n",
       "1        8.005559        17.627335       0.431992              281.76   \n",
       "\n",
       "   total_per_star_rmse  total_per_star_r2  avg_rating_mae  avg_rating_rmse  \\\n",
       "0           928.528169           0.964295            0.07         0.114018   \n",
       "1           957.028735           0.962069            0.08         0.126491   \n",
       "\n",
       "   avg_rating_r2                                         model_name  \\\n",
       "0       0.856195                                       RandomForest   \n",
       "1       0.823009  MultiOutputRegressor with GradientBoostingRegr...   \n",
       "\n",
       "   composite_rmse  composite_mae  composite_r2  \n",
       "0      315.430605      95.838589      0.750348  \n",
       "1      324.927520      96.615186      0.739023  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error and accuracy calculation function\n",
    "pred_gt_pairs = [\n",
    "    (\"RandomForest\", \"variant_predictions_spreadsheet_style_norm.csv\", \"Blank rating calculation - Variant Ground Truth.csv\"),\n",
    "    (\"MultiOutputRegressor with GradientBoostingRegressor\", \"variant_predictions_gboost.csv\", \"Blank rating calculation - Variant Ground Truth.csv\")\n",
    "    # Add more models as needed...\n",
    "]\n",
    "results_df = batch_evaluate(pred_gt_pairs)\n",
    "\n",
    "print(\"MAE (Mean Square Error) - penalizes larger errors more heavily (good if outliers matter to you)\")\n",
    "print(\"RMSE (Root Mean Squared Error) - is more robust to outliers and is the “average error” in the same units as your data\")\n",
    "print(\"R2 (coefficient of determination) - Ranges from 0 to 1, with 1.0 being perfect prediction. Can be interpreted as the proportion of variance explained\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed2b19-78e2-4ccb-aa3a-ac1bbd1ebdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
